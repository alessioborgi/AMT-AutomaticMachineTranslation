{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "eb0051ba",
      "metadata": {
        "id": "eb0051ba"
      },
      "source": [
        "# AMT - AUTOMATIC MACHINE TRANSLATION\n",
        "\n",
        "@alessioborgi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5815e93",
      "metadata": {
        "id": "e5815e93"
      },
      "source": [
        "### 0: IMPORTING LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "dde1395d",
      "metadata": {
        "id": "dde1395d",
        "outputId": "b770b4cf-2d5c-411a-849b-ead3eb5d9557",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (0.31.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (5.29.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (4.13.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U datasets\n",
        "!pip install huggingface-hub pandas transformers tiktoken protobuf sentencepiece tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "dd111d96",
      "metadata": {
        "id": "dd111d96"
      },
      "outputs": [],
      "source": [
        "# Importing libraries for step 1).\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "from huggingface_hub import login\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "\n",
        "# Importing libraries for step 2).\n",
        "from transformers import MBartForConditionalGeneration, MBart50Tokenizer, M2M100ForConditionalGeneration, M2M100Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08f951ed",
      "metadata": {
        "id": "08f951ed"
      },
      "source": [
        "### 1: LOADING THE DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3c5cac4",
      "metadata": {
        "id": "b3c5cac4"
      },
      "source": [
        "#### 1.1: PUSH THE DATASET TO HUGGING-FACE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "317477c9",
      "metadata": {
        "id": "317477c9"
      },
      "outputs": [],
      "source": [
        "def upload_to_hf_dataset(\n",
        "    hf_token: str,\n",
        "    data_file_path: str,\n",
        "    repo_name: str,\n",
        "    file_format: str = \"csv\",\n",
        "    split_name: str = \"test\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Uploads a local file as a Hugging Face Dataset.\n",
        "\n",
        "    Args:\n",
        "        hf_token: Your Hugging Face access token.\n",
        "        data_file_path: Path to the local data file.\n",
        "        repo_name: The target repo on HF (e.g. \"username/my-dataset\").\n",
        "        file_format: One of \"csv\", \"json\", \"tsv\", etc. Default \"csv\".\n",
        "        split_name: Name of the dataset split (e.g. \"train\", \"test\"). Default \"test\".\n",
        "    \"\"\"\n",
        "    # 1) Authenticate to HuggingFace.\n",
        "    login(token=hf_token)\n",
        "\n",
        "    # 2) Load local file.\n",
        "    data_files = { split_name: data_file_path }\n",
        "    dataset = load_dataset(file_format, data_files=data_files)\n",
        "\n",
        "    # 3) Push to Hub.\n",
        "    dataset.push_to_hub(repo_name, token=hf_token)\n",
        "    print(f\"Dataset available at https://huggingface.co/datasets/{repo_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3534962",
      "metadata": {
        "id": "d3534962"
      },
      "outputs": [],
      "source": [
        "hf_token = \"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\"\n",
        "local_path = \"/Users/alessioborgi/GitHub/AMT-AutomaticMachineTranslation/test_data/dataset_cleaned.csv\"\n",
        "repo_name  = \"Alessio-Borgi/archaic-italian-cleaned-test\"\n",
        "\n",
        "upload_to_hf_dataset(\n",
        "    hf_token=hf_token,\n",
        "    data_file_path=local_path,\n",
        "    repo_name=repo_name,\n",
        "    file_format=\"csv\",\n",
        "    split_name=\"test\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab78d895",
      "metadata": {
        "id": "ab78d895"
      },
      "source": [
        "#### 1.2: LOADING DATASET FROM HUGGING-FACE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b45de4f9",
      "metadata": {
        "id": "b45de4f9"
      },
      "outputs": [],
      "source": [
        "ds = load_dataset(\"Alessio-Borgi/archaic-italian-cleaned-test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8a715151",
      "metadata": {
        "id": "8a715151",
        "outputId": "59a89da7-05e5-45c7-ce29-509eb4c5c4f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    test: Dataset({\n",
              "        features: ['Author', 'Date', 'Region', 'Sentence'],\n",
              "        num_rows: 97\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6632166c",
      "metadata": {
        "id": "6632166c"
      },
      "source": [
        "#### 1.3: EXPLORING THE TEST DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e34f5446",
      "metadata": {
        "id": "e34f5446"
      },
      "outputs": [],
      "source": [
        "def explore_dataset(dataset_name):\n",
        "    ''' Function to explore a dataset. '''\n",
        "\n",
        "    # Loading the dataset.\n",
        "    ds = load_dataset(dataset_name)\n",
        "    df = pd.DataFrame(ds[\"test\"])\n",
        "\n",
        "    # 1) Number of examples.\n",
        "    print(\"Number of examples:\", len(df))\n",
        "\n",
        "    # 2) Preview first 5 examples.\n",
        "    print(\"First 5 examples:\")\n",
        "    print(df.head(5), \"\\n\")\n",
        "\n",
        "    # 3) Sentence-length statistics.\n",
        "    df[\"length_tokens\"] = df[\"Sentence\"].apply(lambda x: len(x.split()))\n",
        "    print(\"Sentence length (tokens) stats:\")\n",
        "    print(df[\"length_tokens\"].describe(), \"\\n\")\n",
        "\n",
        "    # 4 Take out the column names.\n",
        "    print(\"Column names:\", df.columns.tolist(), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c325d352",
      "metadata": {
        "id": "c325d352",
        "outputId": "540ce5c0-de9e-44a9-dbb3-314ab0a953f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of examples: 97\n",
            "First 5 examples:\n",
            "                        Author     Date Region  \\\n",
            "0              Brunetto Latini  1260-61  fior.   \n",
            "1                Bono Giamboni     1292  fior.   \n",
            "2     Valerio Massimo (red. V1     1336  fior.   \n",
            "3  Lucano volg. (ed. Marinoni)  1330/40  prat.   \n",
            "4              Brunetto Latini  1260-61  fior.   \n",
            "\n",
            "                                            Sentence  \n",
            "0  quella guerra ben fatta l' opera perché etc. E...  \n",
            "1  crudele, e di tutte le colpe pigli vendetta, c...  \n",
            "2  Non d' altra forza d' animo fue ornato Ponzio ...  \n",
            "3  Se questo piace a tutti e se 'l tempo hae biso...  \n",
            "4  Officio di questa arte pare che sia dicere app...   \n",
            "\n",
            "Sentence length (tokens) stats:\n",
            "count    97.000000\n",
            "mean     20.041237\n",
            "std       5.996384\n",
            "min       6.000000\n",
            "25%      16.000000\n",
            "50%      20.000000\n",
            "75%      24.000000\n",
            "max      31.000000\n",
            "Name: length_tokens, dtype: float64 \n",
            "\n",
            "Column names: ['Author', 'Date', 'Region', 'Sentence', 'length_tokens'] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Explore the dataset.\n",
        "explore_dataset(dataset_name=\"Alessio-Borgi/archaic-italian-cleaned-test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e43c38e6",
      "metadata": {
        "id": "e43c38e6"
      },
      "source": [
        "### 2: AMT - TRANSFORMER-BASED"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd8ef6df",
      "metadata": {
        "id": "cd8ef6df"
      },
      "source": [
        "#### 2.1: mBART (MULTILINGUAL BART)\n",
        "\n",
        "**ARCHITECTURE & SIZE**\n",
        "This Transformer-based solution consists in 12-layer encoder + 12-layer decoder Transformer (≈610 M parameters).\n",
        "\n",
        "**DESCRIPTION**\n",
        "- **Pretraining**: It has been pretrained via Denoising auto-encoding on monolingual corpora in 50 languages (mBART-50).\n",
        "- **Multilingual MT**: It has been fine-tuned on many-to-many bitext and supports direct “it→it” by forcing Italian as both source & target.\n",
        "\n",
        "**REFERENCE INFORMATION**\n",
        "- Hugging-Face Reference page: https://huggingface.co/docs/transformers/model_doc/mbart\n",
        "- Paper: https://arxiv.org/abs/2001.08210\n",
        "- Specific Model employed: *facebook/mbart-large-50-many-to-many-mmt*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1ec3f7d",
      "metadata": {
        "id": "c1ec3f7d",
        "outputId": "0a20fed8-e66e-4eb8-c539-afb69d05d8c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "84b712dd5fa142b889eeecbfc2d7d85f",
            "e8a17540e25b4c3a96c456f08d5d8876",
            "f2ece3780a80448abb54144986c57e5d",
            "155185984bcd49b395f4605ef7682d76",
            "c373d32bfce64df4a6551fe13ef5e7ae",
            "17306f0d150641de962944ec4474dbde",
            "03b49c365e994fd392bf392a76ea389f",
            "73a0163a4d3b49a6bcdc1bfe878751dc",
            "2e2aba59b0394df78b5e1577cfd8cc02",
            "f8a8b2e0a76e4b8da57f7f97579b5714",
            "003dd63f01ae497d8532a57dfb1bbf53"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "mBART Translation:   0%|          | 0/13 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84b712dd5fa142b889eeecbfc2d7d85f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 1) Loading mBART-50 Model & Tokenizer.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "mBART_tokenizer = MBart50Tokenizer.from_pretrained(model_name)\n",
        "mBART_model = MBartForConditionalGeneration.from_pretrained(model_name).to(device)\n",
        "mBART_tokenizer.src_lang = \"it_IT\"\n",
        "mBART_tokenizer.model_max_length = 512\n",
        "\n",
        "\n",
        "# 2) Updated batched translation with device placement\n",
        "def modernize_mbart(sentences, batch_size=8):\n",
        "    \"\"\"\n",
        "    Translate sentences using mBART on GPU (if available),\n",
        "    showing a tqdm progress bar.\n",
        "    \"\"\"\n",
        "    translations = []\n",
        "    total_batches = (len(sentences) + batch_size - 1) // batch_size\n",
        "\n",
        "    for i in tqdm(\n",
        "        range(0, len(sentences), batch_size),\n",
        "        total=total_batches,\n",
        "        desc=\"mBART Translation\",\n",
        "        unit=\"batch\",\n",
        "        leave=True\n",
        "    ):\n",
        "        batch = sentences[i : i + batch_size]\n",
        "\n",
        "        # Tokenization.\n",
        "        inputs = mBART_tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        inputs = { name: tensor.to(device) for name, tensor in inputs.items() }\n",
        "\n",
        "        # Generation of the Translations.\n",
        "        with torch.no_grad():\n",
        "            gen = mBART_model.generate(\n",
        "                **inputs,\n",
        "                forced_bos_token_id=mBART_tokenizer.lang_code_to_id[\"it_IT\"],\n",
        "                max_length=512,\n",
        "            )\n",
        "        translations.extend(mBART_tokenizer.batch_decode(gen, skip_special_tokens=True))\n",
        "    return translations\n",
        "\n",
        "# 3) Run on the test split (replace \"text\" with the actual column name if different)\n",
        "arch_sentences = ds[\"test\"][\"Sentence\"]\n",
        "mbart_outputs = modernize_mbart(arch_sentences)\n",
        "\n",
        "# 4) Attach back to the dataset the translations.\n",
        "ds = ds[\"test\"].add_column(\"mbart_translation\", mbart_outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translated_ds_mbart[\"mbart_translation\"]"
      ],
      "metadata": {
        "id": "gjx2HMnQ7pWf",
        "outputId": "9e2f336a-55af-44dd-f2bf-f5e7c351cc3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "gjx2HMnQ7pWf",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"E poi, Aiaces, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi, un po' di soldi.\",\n",
              " 'Crudele, e per tutte le colpe vendetta, come dice la legge, e per tutte le colpe vendetta, come dice la legge, e per tutte le colpe vendetta.',\n",
              " \"Non c'è altra forza d' animosità che è stato venerato il Ponzio dell'Umiliare, un romano cavaliere.\",\n",
              " 'Se questo piace a tutti e se il tempo ha bisogno di Pompei per ridere e non per compagno, non riterrò più fati.',\n",
              " \"L'offiziere di questo arte sembra essere solo per far credere, fine, per far credere.\",\n",
              " \"E' un' larghezza di vento, e' un' larghezza di nebbia, e' un' larghezza di vento, e' un' larghezza di vento, e' un' larghezza di vento, e' un' larghezza di vento, e' un' larghezza di vento, e' un' larghezza di vento, e' un' larghezza di vento, e' un' larghezza di vento, e' un' larghezza di vento, e' un' larghezza di vento, e' un' larghezza di vento, e' un' larghezza di vento, e' un' larghezza di vento, e' un' larghezza di vento, e' larghezza di vento, e' un' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e' larghezza di vento, e'\",\n",
              " 'Ma those che spero di esporre, those che non vogliono ancora credere in Cristo, sono già con noi, e perché non lo possono negare, sono già con noi.',\n",
              " 'Le vendetta per le morti facevano il frotto di un re feroce.',\n",
              " 'Quello, che ora per le sue grandi reghi è feroce e onorevole, il mal afflitto e tormentato di impiezia verso mio padre.',\n",
              " 'Gli uomini che si fermano nella bugia incontrano la verità.',\n",
              " \"Marco Cornelio, all'incidence, and all'incidence, and all'incidence, and all'incidence, and all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, e all'incidence, eincidence, e all'incidence, eincidence, eincidence, eincidence, eincidence, eincidence, eincidence, eincidence, eincidence, eincidence, eincidence, eincidence, eincidence, eincidence, einci\",\n",
              " 'Le cose che io sapevo erano fatte in Italia.',\n",
              " 'Corbio, nephew of Ortensio, ha fatto la vita più bassa e più visiva.',\n",
              " 'Allora, un amante che chiama la sua donna dice molte parole e ragioni, e lei si difende in quello che dice.',\n",
              " 'Io ricordo che, being adirato, mi scappò la donna. Oh, come mi ha tolto la rabbina!',\n",
              " \"Quello che dovere fare era l'amore della tua donna.\",\n",
              " \"Ma non c'è il numero delle sue congiurati, perché la donna non li ha già nominati.\",\n",
              " 'Crete? Certo, quando lui si muove, lui ti dice: \"O fedele mia donna, fate in mio posto il nostro hoste troiano.\"',\n",
              " \"In Milano, la malvagia di una donna simile, all'epoca di questo signore della Repubblica, è stata repressa in questo modo.\",\n",
              " \"E lamentavano l'inquità di Appio, e ricordavano la malventura della pulcella e la necessità del padre.\",\n",
              " 'In quale battaglia, certo, io ho sempre pensato di pace, e mi sono sempre fatto che non solo la pace era schiacciata.',\n",
              " 'Il secondo suole non è per la grande abilità di far ridere, e il primo suole per la grande abilità di far ridere.',\n",
              " \"E' andato a campo di Cartagena, e' andato a campo di Cartagena, e' andato a campo di Cartagena, e' andato a campo di Cartagena, e' andato a campo di Cartagena.\",\n",
              " 'Non voleva sapere per niente. Questa è la persona che ha chiesto al profeta Natan di riprendere con grande autorità il re che aveva peccato.',\n",
              " \"l'armi e con loro passavano tra i nullai, quindi se non c'era un'armi e non c'era un'armi, loro passavano tra i nullai, quindi se non c'era un'armi e non c'era un'armi.\",\n",
              " 'E none deluso di Iob.',\n",
              " 'Quello che perdono per i cittadini, e che most di sicuro voi possiate credere; e poi lui fu il vostro capo.',\n",
              " \"In vano si chiede chi abbia scritto questo libro, con il quale crediamo che l'autore di questo abbia fusto il Santo Spirit.\",\n",
              " \"Se non'era molto usata, questo sarebbe certamente molto più incredibile: Certamente più efficace di credere in quello, posto che l'uomo spirite al divino, e il mutabile al incommutatbile.\",\n",
              " 'che pagavano il camarlingo per la loro dispensazione, e continuamente andavano alla presenza del papato per contraddire il passaggio dei cavalieri che venivano da Cecilia in Toscana.',\n",
              " 'Teseo guardò Achelao con grande splendor, e disse, \"O Messiah Achelao, please tell me how you\\'ve perso.',\n",
              " \"Io spero, in Messier Iesù, di mandare un tosto a Timoteo, perche' io abbia un buon umore.\",\n",
              " \"sanza fa il sacco, e l'uomo fa sentire, e l'uomo fa vedere.\",\n",
              " 'Un posto dove. Un posto dove dove. Un posto dove dove. Un posto dove dove. Un posto dove dove. Un posto dove dove.',\n",
              " 'Tende le reti e sa bene quali vallei scorrono.',\n",
              " 'Ora vi spaventate di fronte a diverse predizioni, o lo sto scacchiando in terra con il collo stretto.',\n",
              " 'tratta la natura delle cose incorporate che non parlano nei loro corpi, proprio come Dio e le cose divine.',\n",
              " 'Dio, per cui dispensano e judicano tutto.',\n",
              " 'Quando i poeti, parlando di lei, parlando di virtue, parlando di difetto, quando i poeti, parlando di lei, parlando di virtue, parlando di difetto, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei, parlando di lei,',\n",
              " 'E quella, che è diritta et onesta, e con virtue, quella, che io penso sia il bene.',\n",
              " \"Quando i serpenti invecchiano, non c'è Romano, then c'è la meraviglia di vedere i Psilli combattersi il veleno, che impugnano tutto il loro salive.\",\n",
              " 'La poetessa dice, \"Oh, che bella cosa è vedere con gli occhi aperti quando lo fai in faccia o in colpo o in altro.\"',\n",
              " \"Ma nonetheless, it's your fault, che cercate di vedere l'invisibile con i vostri occhi.\",\n",
              " 'È vero, ma non ti risponde in questo tempo, perché ttu è il mio servo, o perché è il mio tempo, o perché non devo rispondere.',\n",
              " \"E' un po' che dia loro il grande per farli andare via.\",\n",
              " \"Un'esempio notevole per chi guardava di fare e di pensare tradigione, il servitore, che accusava, fu francato, e fuggito, donate un'esempio notevole di moneta.\",\n",
              " 'Che cosa sarebbe successo a lui se avesse fatto in modo che la colpa del servitore e la gratificazione di Platone avesse meritato in modo equo.',\n",
              " 'mostre le sue forze, dandogli il potere di questa città in cui sono nato, in cui sono nato, in cui sono nato, in cui sono nato per molto tempo.',\n",
              " \"L'anima muta la forza per la propietazione del corpo con cui si unisce.\",\n",
              " \"Ci sono due, non in un corpo, ma in un spirito, ossia l'Idio, e l'anima. E' un altro punto in cui dice S. Paolo: Chi si avvicina a Dio è un spirito.\",\n",
              " \"Per quanto Lucano l'ha detto, l'abbiamo raccontato a voi. A voi, quando l'anima di Pompeo ebbe sentito la clarità di lassù, lei sì cognobe prima in grande.\",\n",
              " \"Perché il dolore è ascoltato, quando si usa l'arma e la difficoltà si rispondono, con grande disonore come le pecore siano.\",\n",
              " 'E nonn had Christ in fasti, words da ascoltare.',\n",
              " 'La grandezza che hai visto e che riguarda lo studio, e che, poco fa, hai sentito le voci, e che, poco fa, hai sentito le voci, e che, poco fa, hai sentito le voci.',\n",
              " 'Udire belle fiori, e udire belle fiori, e udire belle fiori, e udire belle fiori, e udire belle fiori, e udire belle fiori, e udire belle fiori.',\n",
              " 'Il re entrò in un giardino dietro al suo hotel, quasi mentre pensava alla risposta.',\n",
              " 'Ma io gioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioioio',\n",
              " \"All'improvviso, all'incertezza degli uccelli si alza dietro l'aquila.\",\n",
              " 'Vede anche le ragioni per cui gli uccelli volano, e tutte le cose per cui gli uccelli volano, e vede anche le ragioni per cui gli uccelli volano, e tutte le cose per cui gli uccelli volano, e vede tutte le cose per cui gli uccelli volano, e vede tutte le cose per cui gli uccelli volano, e vede tutte le cose per cui gli uccelli volano, e vede tutte le cose per cui gli uccelli volano, e vede tutte le cose per cui gli uccelli volano, e vede tutte le cose per cui gli uccelli volano, e vede tutte le cose per cui gli uccelli volano.',\n",
              " \"E' questo che per la sua superba, questo uccello vola in alto.\",\n",
              " 'Sono gorgo, e ho la proprietà di volare per l\\'aria come un uccello.\"',\n",
              " 'quando si scritte per Dio, per Cristo, per il Santo Spirit.',\n",
              " \"per il ridicolo che, secondo il tuo comandamento, Padre Sant'Agostino, le battaglie sono già nel mondo [...]\",\n",
              " 'Molte più memoriale li fareranno al re, perché nella nostra città era sempre sacro e glorioso il nome reale, e se erano compagni era il nome molto sacro.',\n",
              " 'Non voglio che tubbi per la sacredità, che tubbi per la vergine, che tubbi per la vergine, che tubbi per la vergine.',\n",
              " 'Sant\\'Agostino wrote a book called \"Agostino della Città di Dio.\"',\n",
              " 'Gregorio. Non avrete mai un maestro, ma il dono del Santo Spirit non si può stringere.',\n",
              " 'Verbose: Merchant fiorecchini che andavano in nave a galleggiare.',\n",
              " \"Quando si trovate in un'esercito, i segni non vanno in grandezza, perché in combattimento i forti sono più utili.\",\n",
              " 'E, cosa ancora più grave, di essere catturato, o realmente fuggito, e lasciare che il suo Comune vinca.',\n",
              " \"Sapete, se non' fossimo affetti da fuggire, saremmo tutti morti.\",\n",
              " \"Tarco credeva che per aiutare i nipoti poteva fuggire, ma la vergogna di abbandonare i nobili cavalieri della gente lo faceva un po' di più.\",\n",
              " \"E' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose cose, e' l'abitudine a fare grandiose, e' l'abitudine a fare grandiose, e' l'abitudine a fare grandiose, e' l'abitudine a fare grandiose, e' l'abitudine a fare grandiose, a fare grandiose, e' l'abitudine a fare grandiose, e' l'abitudine a fare grandiose, a fare grandiose, e' l'abitudine a fare grandiose, a fare grandi\",\n",
              " 'Quello che non sa amare il prossimo come lui stesso inizia a temere i giudizi di Dio.',\n",
              " \"L'uccello, che ha splendid ali, non esca salvamentementementementementementementementementementementementementementementementementementementementementementementementementementementementementementementementemente.\",\n",
              " 'Io apro, e quelli che fuggino. E che cosa serve, che il tuo cuore sia chiuso al tuo marito Cristo?',\n",
              " \"E therefore, since these things are, Cattina, and you can't sleep bene, do you dare to get in any land and use this life to scarabocchiare?\",\n",
              " 'Questi due, volando controversie in the tribunale, sono morti per la tribù, incoraggiando i padri coscritti.',\n",
              " \"I don't know. I don't know. I don't know.\",\n",
              " 'Nei monti dei Romani si fecero nuovi nemici, contro i quali è combattuto cum different ventura: perké in prima battaglia, da consolato Valerio, MMMD è morto dai Romani.',\n",
              " 'Siamo stati debiti della città, e siamo stati debiti di fama e di successo.',\n",
              " 'Seppelli per me; your preghiere valgono; e seppelli per me; seppelli per me; e seppelli per me.',\n",
              " \"Una villa called Vitermina, and that's what the most sacro-scientifico principe che've mai visto, Scipione, che've mai visto, che've mai visto, che've mai visto, che've mai visto, che've mai visto, che've mai visto, che've mai visto, che've mai visto, che've mai visto.\",\n",
              " 'controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, controversy, contro',\n",
              " \"Quando il navio è stato impinto e messo in alto mare per andare dritto per mezzo, questo trapianto periglio, l'aria è diventata nuvola e piovegina.\",\n",
              " \"Io salto sull'argilla del fosso, e sull'imbarcazione, se da alto potevano difendersi, o in qualche modo andare oltre e scampire.\",\n",
              " \"Ma l'occhio dell'intelligenza è più alto. Quindi, oltre la grandezza dell'università, quella semplice forma vede nella sottile vista.\",\n",
              " \"E se l'occhio è un nobile membro del corpo dell'uomo, quindi il saluto è un nobile membro del pistolo, allora l'occhio illumina la lettera come l'occhio illumina l'uomo.\",\n",
              " 'Tarentini, who were born of those of Lacedemonia e di quella nobile cittade greci.',\n",
              " 'Ulecois, ebbe un uomo nobile: Orgentore è stato chiamato per nome.',\n",
              " 'Ma che, nobile cosa e alta è abatte il nulla, ampoi nonn è meno gratificabile sapere che ci sono delle contraddizioni.',\n",
              " \"Alexandro, that's the generous, and the cucciolo, from Phausonia, a gentile ebreo di Macedonia, stand in un punto stretto di guardian, è morto.\",\n",
              " \"Anche lui è ricco e gentile, ma lamentandosi di avere un'altra moglie che lui.\",\n",
              " 'Pietro, visto il popolo Gentile, si è detto: ammala, e mangia.',\n",
              " \"Permettete me di liberarlo di quella obbligazione, in cui l'aveva abbandonato. Il gentile uomo si sedette, e si liberò, e fece carta.\",\n",
              " \"L'oro verrà dall'Aquilone. Che non siamo noi per l'Aquilone, se non la popolazione Gentile congelata dal freddo del peccato, che la popolazione tenne sotto il gioco della sua tirannia.\",\n",
              " \"E' in between me e te: none of us can diede più, none of me will sofferre e none of me will leave.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2914d9a9",
      "metadata": {
        "id": "2914d9a9"
      },
      "source": [
        "#### 2.2: NLLB (No Language Left Behind)\n",
        "\n",
        "**ARCHITECTURE & SIZE**\n",
        "This Transformer-based solution comes from the Meta family. It's a many-to-many multilingual Seq2Seq that can be used as a rewriting model for Italian→Italian..\n",
        "\n",
        "**DESCRIPTION**\n",
        "- **High Capacity/Quality**: The flagship nllb-200-3.3B has shown state-of-the-art BLEU/COMET on many low-resource ↔ high-resource pairs, and handles morphological/orthographic variation robustly.\n",
        "- **Multilingual MT**: It supports 200 languages and has full support for ita_Latn (Italian in Latin script).\n",
        "\n",
        "**REFERENCE INFORMATION**\n",
        "- Hugging-Face Reference page: https://huggingface.co/docs/transformers/en/model_doc/nllb\n",
        "- Paper: https://arxiv.org/abs/2207.04672\n",
        "- Specific Model employed: *facebook/nllb-200-3.3B*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f5bbff7",
      "metadata": {
        "id": "6f5bbff7"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Translate with NLLB-200-3.3B\n",
        "\n",
        "\n",
        "# 2) Load NLLB-200-3.3B model & tokenizer\n",
        "model_name = \"facebook/nllb-200-3.3B\"\n",
        "tokenizer = M2M100Tokenizer.from_pretrained(model_name)\n",
        "model = M2M100ForConditionalGeneration.from_pretrained(model_name)\n",
        "tokenizer.src_lang = \"ita_Latn\"\n",
        "\n",
        "# 3) Batched translation function\n",
        "def modernize_nllb(sentences, batch_size=8):\n",
        "    translations = []\n",
        "    for i in range(0, len(sentences), batch_size):\n",
        "        batch = sentences[i : i + batch_size]\n",
        "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        gen = model.generate(\n",
        "            **inputs,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[\"ita_Latn\"],\n",
        "            max_length=512,\n",
        "        )\n",
        "        translations.extend(tokenizer.batch_decode(gen, skip_special_tokens=True))\n",
        "    return translations\n",
        "\n",
        "# 4) Run on your test split (replace \"text\" with the actual column name if different)\n",
        "arch_sentences = ds[\"test\"][\"text\"]\n",
        "nllb_outputs = modernize_nllb(arch_sentences)\n",
        "\n",
        "# 5) (Optional) Attach back to the dataset\n",
        "translated_ds_nllb = ds[\"test\"].add_column(\"nllb_translation\", nllb_outputs)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "84b712dd5fa142b889eeecbfc2d7d85f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8a17540e25b4c3a96c456f08d5d8876",
              "IPY_MODEL_f2ece3780a80448abb54144986c57e5d",
              "IPY_MODEL_155185984bcd49b395f4605ef7682d76"
            ],
            "layout": "IPY_MODEL_c373d32bfce64df4a6551fe13ef5e7ae"
          }
        },
        "e8a17540e25b4c3a96c456f08d5d8876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17306f0d150641de962944ec4474dbde",
            "placeholder": "​",
            "style": "IPY_MODEL_03b49c365e994fd392bf392a76ea389f",
            "value": "mBART Translation:  31%"
          }
        },
        "f2ece3780a80448abb54144986c57e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73a0163a4d3b49a6bcdc1bfe878751dc",
            "max": 13,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e2aba59b0394df78b5e1577cfd8cc02",
            "value": 4
          }
        },
        "155185984bcd49b395f4605ef7682d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8a8b2e0a76e4b8da57f7f97579b5714",
            "placeholder": "​",
            "style": "IPY_MODEL_003dd63f01ae497d8532a57dfb1bbf53",
            "value": " 4/13 [01:08&lt;01:47, 11.90s/batch]"
          }
        },
        "c373d32bfce64df4a6551fe13ef5e7ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17306f0d150641de962944ec4474dbde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03b49c365e994fd392bf392a76ea389f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73a0163a4d3b49a6bcdc1bfe878751dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e2aba59b0394df78b5e1577cfd8cc02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8a8b2e0a76e4b8da57f7f97579b5714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "003dd63f01ae497d8532a57dfb1bbf53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}